{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN \n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoRoot = \"./Data/Coco/\"\n",
    "dataType = \"val2017\"\n",
    "\n",
    "annFile = os.path.join(cocoRoot, f'annotations/instances_{dataType}.json')\n",
    "print(f'Annotation file: {annFile}')\n",
    "\n",
    "coco=COCO(annFile)\n",
    "coco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "def plot_image_with_annotations(coco, cocoRoot, dataType, imgId, ax=None):\n",
    "    # Get image information\n",
    "    imgInfo = coco.loadImgs(imgId)[0]\n",
    "    # Get image location for visualization\n",
    "    imPath = os.path.join(cocoRoot, dataType, imgInfo['file_name'])    \n",
    "    # Read the image\n",
    "    im = cv2.imread(imPath)\n",
    "    # Convert color space: OpenCV defaults to BGR, but matplotlib to RGB, so conversion is needed\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all annotations (bounding boxes) for the image\n",
    "    annIds = coco.getAnnIds(imgIds=imgInfo['id'])\n",
    "    # Load all annotation information: bounding box coordinates, labels, accuracies\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    all_labels = set()\n",
    "\n",
    "    # Extract bounding box coordinates, labels, accuracies\n",
    "    for ann in anns:\n",
    "        # Specifically select information related to the bounding box: returns (x, y) of the lower-left corner, width, height\n",
    "        x, y, w, h = ann['bbox']\n",
    "\n",
    "        # Get label text information: load category name by category ID\n",
    "        label = coco.loadCats(ann['category_id'])[0][\"name\"]\n",
    "        all_labels.add(label)\n",
    "\n",
    "        # Draw bounding boxes using provided coordinates\n",
    "        rect = Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    \n",
    "        # Draw the image: if sorting of images is needed, ax parameter specifies the position\n",
    "        if ax is None:\n",
    "            plt.gca().add_patch(rect) \n",
    "            plt.text(x, y, f'{label}', fontsize=10, color='w', backgroundcolor='r')\n",
    "        else:\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x, y, f'{label}', fontsize=10, color='w', backgroundcolor='r')\n",
    "\n",
    "    # Display the image with a title\n",
    "    if ax is None:\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Annotations: {all_labels}', color='r')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Annotations: {all_labels}', color='r', loc='center', pad=20)\n",
    "        ax.imshow(im)\n",
    "\n",
    "\n",
    "# Get the tenth image\n",
    "imgIds = coco.getImgIds()\n",
    "imgId = imgIds[10]\n",
    "\n",
    "plot_image_with_annotations(coco, cocoRoot, dataType, imgId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(coco, cocoRoot, dataType, num_images=10):\n",
    "    \n",
    "    imgIds = coco.getImgIds()\n",
    "    \n",
    "    selected_imgIds = random.sample(imgIds, num_images)\n",
    "    \n",
    "    for imgId in selected_imgIds:\n",
    "        \n",
    "        plot_image_with_annotations(coco, cocoRoot, dataType, imgId)\n",
    "    \n",
    "    \n",
    "    return selected_imgIds\n",
    "    \n",
    "valid_ids = random_select(coco, cocoRoot, dataType, num_images=10)\n",
    "valid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_res = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"RCNN_ResNet50_FPN_Weights.DEFAULT\")\n",
    "model_res.eval()\n",
    "\n",
    "model_mobile = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights=torchvision.models.detection.RCNN_MobileNet_V3_Large_FPN_Weights)\n",
    "model_mobile.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(imgIdx):\n",
    "    \n",
    "    imgInfo = coco.loadImgs(imgIdx)[0]\n",
    "    \n",
    "    imPath = os.path.join(cocoRoot, dataType, imgInfo['file_name'])    \n",
    "    \n",
    "    print(imPath)\n",
    "    try:\n",
    "         \n",
    "        return Image.open(imPath)\n",
    "    except:\n",
    "        raise Exception()\n",
    "\n",
    "\n",
    "def pil2tensor(pil_image):\n",
    "    \n",
    "    return torchvision.transforms.PILToTensor()(pil_image).unsqueeze(0) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "predictions_res = []\n",
    "predictions_mobile = []\n",
    "\n",
    "for i in valid_ids:\n",
    "    print(i)\n",
    "    \n",
    "    img_as_tensor = pil2tensor(load_image(i))\n",
    "   \n",
    "    prediction = model_res(img_as_tensor)\n",
    "    \n",
    "    predictions_res.append(prediction)\n",
    "\n",
    "    prediction = model_mobile(img_as_tensor)\n",
    "    \n",
    "    predictions_mobile.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_boxes(predictions, threshold=0.8):\n",
    "    \n",
    "    valid_boxes_list = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        valid_boxes_for_this_prediction = []\n",
    "        \n",
    "        for box, label, score in zip(prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]):\n",
    "            \n",
    "            if score >= threshold: \n",
    "                \n",
    "                valid_boxes_for_this_prediction.append((box, label, score))\n",
    "        \n",
    "        valid_boxes_list.append(valid_boxes_for_this_prediction)\n",
    "    \n",
    "    return valid_boxes_list\n",
    "\n",
    "\n",
    "valid_boxes_res = filter_valid_boxes(predictions_res, threshold=0.8)\n",
    "valid_boxes_mobile = filter_valid_boxes(predictions_mobile, threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    " \n",
    "def display_annotated_results(imgId, valid_boxes, model_name, color='g', ax=None):\n",
    "    \n",
    "    imgInfo = coco.loadImgs(imgId)[0]\n",
    "    image_path = os.path.join(cocoRoot, dataType, imgInfo['file_name'])\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    \n",
    "    annIds = coco.getAnnIds(imgIds=imgInfo['id'])\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    bbox_tlist_anns = torch.tensor([ann[\"bbox\"] for ann in anns]) # tensor.shape[2,4]\n",
    "   \n",
    "    bbox_tlist_anns[:, 2] = bbox_tlist_anns[:, 0] + bbox_tlist_anns[:, 2]\n",
    "    bbox_tlist_anns[:, 3] = bbox_tlist_anns[:, 1] + bbox_tlist_anns[:, 3]\n",
    "    \n",
    "    \n",
    "    bbox_tlist_model = torch.stack([box for box, _, _ in valid_boxes]) \n",
    "    \n",
    "    iou = torchvision.ops.box_iou(bbox_tlist_anns, bbox_tlist_model) \n",
    "    \n",
    "    avg_iou = np.mean([t.cpu().detach().numpy().max() for t in iou]) \n",
    "    \n",
    "    all_labels = set()\n",
    "\n",
    "    \n",
    "    for boxes in valid_boxes:\n",
    "        \n",
    "        box, label, score = boxes\n",
    "\n",
    "        label = coco.loadCats(label.item())[0][\"name\"]\n",
    "        \n",
    "        all_labels.add(label)\n",
    "        \n",
    "        x, y, x2, y2 = box.detach().numpy() \n",
    "        rect = Rectangle((x, y), x2 - x, y2 - y, linewidth=2, edgecolor=color, facecolor='none')\n",
    "\n",
    "        \n",
    "        if ax is None:\n",
    "            \n",
    "            plt.gca().add_patch(rect) \n",
    "             \n",
    "            plt.text(x, y, f'{label}', fontsize=10, color='w', backgroundcolor=color)\n",
    "        else:\n",
    "            \n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            ax.text(x, y, f'{label}', fontsize=10, color='w', backgroundcolor=color)\n",
    "    \n",
    "    \n",
    "    if ax is None:\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{model_name}: {all_labels} \\n IoU: {avg_iou:.4f}', color=color)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{model_name}: {all_labels} \\n I0U: {avg_iou:.4f}', color=color)\n",
    "        ax.imshow(image)\n",
    "    \n",
    "    return avg_iou\n",
    "\n",
    "\n",
    "res_iou = []\n",
    "mobile_iou = []\n",
    "\n",
    "\n",
    "for i in range(len(valid_ids)):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    \n",
    "    plot_image_with_annotations(coco, cocoRoot, dataType, valid_ids[i], ax=axs[1])\n",
    "\n",
    "    \n",
    "    i_mobil_iou = display_annotated_results(valid_ids[i], valid_boxes_mobile[i], \"mobile\", color='g', ax=axs[0])\n",
    "    i_res_iou = display_annotated_results(valid_ids[i], valid_boxes_res[i], \"ResNet\", color='b', ax=axs[2])\n",
    "\n",
    "    \n",
    "    mobile_iou.append(i_mobil_iou)\n",
    "    res_iou.append(i_res_iou)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "print(\"ResNet: Avg.\", np.mean(res_iou), \"; each IoU:\", res_iou)\n",
    "print(\"MobileNet: Avg.\", np.mean(mobile_iou), \"; each IoU:\", mobile_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.ops.box_iou(bbox_tlist_anns, bbox_tlist_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_iou = np.mean([t.cpu().detach().numpy().max() for t in iou]) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
